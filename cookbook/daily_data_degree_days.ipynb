{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Cooling/Heating Degree Days using daily projections from Cal-Adapt API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through how we calculate Cooling and Heating Degree days for a county.\n",
    "\n",
    "### Step 1. Select location\n",
    "The daily maximum and minimum temperature datasets we will use in this exercise are raster datasets with a grid cell size of 1/16º (approximately 6 km). You can download data for an individual grid cell that corresponds to your area of interest or download data aggregated by a county boundary, watershed, etc. For a list of boundary layers supported by Cal-Adapt please see the API documentation. For this exercise we will use a county boundary from the County Boundaries data available through the Cal-Adapt API.\n",
    "\n",
    "### Step 2. Download data\n",
    " - Download [observed daily maximum & minimum temperatures](http://cal-adapt.org/data/livneh/) for an area or grid cell.\n",
    " - Download [projected daily maximum & minimum temperatures](http://cal-adapt.org/data/loca/) for the location. We will use the 4 priority models and RCP 8.5 scenario (HadGEM2-ES, CNRM-CM5, CanESM2, MIROC5 models have been selected by [California’s Climate Action Team Research Working Group](http://climatechange.ca.gov/climate_action_team/research.html) as [priority models for research](http://docketpublic.energy.ca.gov/PublicDocuments/16-IEPR-04/TN215798_20170207T111409_Projected_Climate_Scenarios_Selected_to_Represent_a_Range_of_Po.pdf) contributing to California’s Fourth Climate Change Assessment).\n",
    " \n",
    "### Step 3. Calculate Degree Days\n",
    " \n",
    " \n",
    "You can modify this approach for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A 'magic' command to display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Import all python modules. You need to run this cell for the other cells to work.\n",
    "import requests \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cal-Adapt API\n",
    "api = 'http://api.cal-adapt.org/api'\n",
    "headers = {'ContentType': 'json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1. Select location\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `g` (geometry parameter) is used to download data for a point, line or polygon. Geometry can be written in various formats including WKT, GeoJSON, KML. The examples below use WKT (Well Known Text) format.\n",
    "\n",
    "#### To get data for a grid cell ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point = 'POINT(-121.4687 38.5938)'\n",
    "data_download_params = {'g': point}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get data for a user defined polygon ...\n",
    "\n",
    "The `stat` parameter is used to spatially aggregate grid cell values. Accepted values are `mean`, `max`, `min`, `count`, `median`, `std`, `var`. If you don't provide the `stat` parameter the API will return an array of grid cell values.\n",
    "\n",
    "You can create a new polygon using this [online WKT editor](https://arthur-e.github.io/Wicket/sandbox-gmaps3.html) or any GIS software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polygon = 'POLYGON ((-123.35449 39.09596, -122.27783 39.09596, -122.27783 39.97712, -123.35449 39.97712, -123.35449 39.09596))' \n",
    "data_download_params = {'g': polygon, 'stat': 'mean'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get data for a polygon using one of the boundary layers in Cal-Adapt API\n",
    "\n",
    "Instead of passing raw geometry like we did earlier using the `g` parameter, you can use a polygon from boundary layers stored in the Cal-Adapt API. You need to know the `id` for this polygon and the boundary layer name. The cells below has code for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_polygon(intersecting_point, boundary):\n",
    "    # Request url\n",
    "    url = api + '/' + boundary + '/'\n",
    "    # Request params\n",
    "    params = {'intersects': intersecting_point, 'srs': 4326, 'simplify': .0001, 'precision': 4}\n",
    "    # Make API request\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        feature = data['features'][0]\n",
    "        if (feature):\n",
    "            return feature\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': '/api/counties/34/', 'stat': 'mean'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your point of interest\n",
    "point = 'POINT(-121.4687 38.5938)'\n",
    "\n",
    "# Name of boundary layer in API (Counties)\n",
    "resource = 'counties'\n",
    "\n",
    "# Polygon feature from resource that intersects your point\n",
    "county = get_polygon(point, resource)\n",
    "\n",
    "ref = '/api/%s/%s/' % (resource, county['id'])\n",
    "data_download_params = {'ref': ref, 'stat': 'mean'}\n",
    "data_download_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2. Download data\n",
    "----\n",
    "\n",
    "**Note: Requests might time out if the polygon is too large. If you need to process data for several boundaries we recommend downloading the daily rasters and processing the data locally.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily data is stored as a multiband raster, e.g. observed daily timeseries (1950 -2013) has 23376 bands with each band corresponding to one day, starting from 1950-01-01. Units for the observed data are degrees Celsius and projected data are in Kelvin.\n",
    "\n",
    "The code in the next cell contains a bunch of functions to:\n",
    "    - fetch daily data given a slug and query parameters\n",
    "    - convert units to degrees F\n",
    "    - return a new Pandas dataframe with the daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def celsius_to_F(val):\n",
    "    return val * 9/5 + 32\n",
    "\n",
    "def kelvin_to_F(val):\n",
    "    return  (val - 273.15) * 9/5 + 32\n",
    "\n",
    "def process_daily_data(item, params):\n",
    "    # Create slug\n",
    "    slug = '_'.join(item)\n",
    "    \n",
    "    # Make request\n",
    "    url = api + '/series/' + slug + '/rasters/'\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Get data\n",
    "    if response.ok:\n",
    "        print('Processing:', slug)\n",
    "        json = response.json()\n",
    "        data = json['results'][0]\n",
    "\n",
    "        # Multiband raster data is returned by the API as a 3D array having a shape like (233376, 1, 1)\n",
    "        # Flatten the 3D array into a 1D array\n",
    "        values_arr = np.array(data['image'])\n",
    "        values_arr = values_arr.flatten()\n",
    "\n",
    "        # Get total number of values -> number of days\n",
    "        length = len(values_arr)\n",
    "\n",
    "        # Get start date of timeseries\n",
    "        start_date = datetime.strptime(data['event'], '%Y-%m-%d')\n",
    "\n",
    "        # Create new pandas dataframe and map each value in list to a date index\n",
    "        df = pd.DataFrame(\n",
    "            values_arr,\n",
    "            index=pd.date_range(start_date, freq='1D', periods=length),\n",
    "            columns=['value'],\n",
    "        )\n",
    "\n",
    "        # Convert units to Fahrenheit\n",
    "        units = data['units']\n",
    "        if units == 'C':\n",
    "            df.value = df.value.apply(lambda x: celsius_to_F(x))\n",
    "        elif units == 'K':\n",
    "            df.value = df.value.apply(lambda x: kelvin_to_F(x))\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # Add climatevar as a column\n",
    "        df['climvar'] = item[0]\n",
    "    else:\n",
    "        print('Failed to download:', slug)\n",
    "            \n",
    "    # Combine all the dataframes into one and return\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get observed historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_observed():\n",
    "    # Create an empty list to hold dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # Make a combined list of GCMs, scenarios, climate variables for looping\n",
    "    climvar = ['tasmax', 'tasmin']\n",
    "    period = ['day']\n",
    "    zipped = itertools.product(climvar, period, ['livneh'])\n",
    "\n",
    "    # Loop through zipped\n",
    "    for item in zipped:\n",
    "        df = process_daily_data(item, data_download_params)\n",
    "        df_list.append(df)\n",
    "            \n",
    "    # Combine all the dataframes into one and return\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: tasmax_day_livneh\n",
      "Processing: tasmin_day_livneh\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>climvar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>47.537341</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-02</th>\n",
       "      <td>43.417568</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-03</th>\n",
       "      <td>46.940557</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-04</th>\n",
       "      <td>43.705381</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-05</th>\n",
       "      <td>45.215155</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-06</th>\n",
       "      <td>48.405793</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-07</th>\n",
       "      <td>50.585093</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-08</th>\n",
       "      <td>50.540371</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-09</th>\n",
       "      <td>50.566721</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-10</th>\n",
       "      <td>49.278330</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-11</th>\n",
       "      <td>49.478000</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-12</th>\n",
       "      <td>49.489319</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-13</th>\n",
       "      <td>45.334659</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-14</th>\n",
       "      <td>45.326494</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-15</th>\n",
       "      <td>48.637196</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-16</th>\n",
       "      <td>44.801341</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-17</th>\n",
       "      <td>53.633589</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-18</th>\n",
       "      <td>59.157918</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-19</th>\n",
       "      <td>62.855898</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-20</th>\n",
       "      <td>65.072311</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-21</th>\n",
       "      <td>62.851444</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-22</th>\n",
       "      <td>65.283299</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-23</th>\n",
       "      <td>62.875012</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-24</th>\n",
       "      <td>57.312455</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-25</th>\n",
       "      <td>50.172021</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-26</th>\n",
       "      <td>45.899155</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-27</th>\n",
       "      <td>49.571340</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-28</th>\n",
       "      <td>48.092186</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-29</th>\n",
       "      <td>49.093506</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-30</th>\n",
       "      <td>50.524227</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-02</th>\n",
       "      <td>39.332309</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-03</th>\n",
       "      <td>40.967712</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-04</th>\n",
       "      <td>32.721670</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-05</th>\n",
       "      <td>27.163567</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-06</th>\n",
       "      <td>25.531320</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-07</th>\n",
       "      <td>29.484454</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-08</th>\n",
       "      <td>26.594804</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-09</th>\n",
       "      <td>23.059196</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-10</th>\n",
       "      <td>25.975196</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-11</th>\n",
       "      <td>27.676846</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12</th>\n",
       "      <td>28.896392</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-13</th>\n",
       "      <td>31.771010</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-14</th>\n",
       "      <td>31.233794</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-15</th>\n",
       "      <td>31.070309</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-16</th>\n",
       "      <td>33.614804</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-17</th>\n",
       "      <td>38.564804</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-18</th>\n",
       "      <td>39.707526</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-19</th>\n",
       "      <td>38.409113</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-20</th>\n",
       "      <td>38.688206</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-21</th>\n",
       "      <td>33.376350</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-22</th>\n",
       "      <td>32.342186</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-23</th>\n",
       "      <td>34.412557</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-24</th>\n",
       "      <td>37.351196</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-25</th>\n",
       "      <td>32.770845</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-26</th>\n",
       "      <td>33.664722</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-27</th>\n",
       "      <td>33.331815</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-28</th>\n",
       "      <td>32.671196</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-29</th>\n",
       "      <td>33.876083</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>36.171361</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>37.504474</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46752 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                value climvar\n",
       "1950-01-01  47.537341  tasmax\n",
       "1950-01-02  43.417568  tasmax\n",
       "1950-01-03  46.940557  tasmax\n",
       "1950-01-04  43.705381  tasmax\n",
       "1950-01-05  45.215155  tasmax\n",
       "1950-01-06  48.405793  tasmax\n",
       "1950-01-07  50.585093  tasmax\n",
       "1950-01-08  50.540371  tasmax\n",
       "1950-01-09  50.566721  tasmax\n",
       "1950-01-10  49.278330  tasmax\n",
       "1950-01-11  49.478000  tasmax\n",
       "1950-01-12  49.489319  tasmax\n",
       "1950-01-13  45.334659  tasmax\n",
       "1950-01-14  45.326494  tasmax\n",
       "1950-01-15  48.637196  tasmax\n",
       "1950-01-16  44.801341  tasmax\n",
       "1950-01-17  53.633589  tasmax\n",
       "1950-01-18  59.157918  tasmax\n",
       "1950-01-19  62.855898  tasmax\n",
       "1950-01-20  65.072311  tasmax\n",
       "1950-01-21  62.851444  tasmax\n",
       "1950-01-22  65.283299  tasmax\n",
       "1950-01-23  62.875012  tasmax\n",
       "1950-01-24  57.312455  tasmax\n",
       "1950-01-25  50.172021  tasmax\n",
       "1950-01-26  45.899155  tasmax\n",
       "1950-01-27  49.571340  tasmax\n",
       "1950-01-28  48.092186  tasmax\n",
       "1950-01-29  49.093506  tasmax\n",
       "1950-01-30  50.524227  tasmax\n",
       "...               ...     ...\n",
       "2013-12-02  39.332309  tasmin\n",
       "2013-12-03  40.967712  tasmin\n",
       "2013-12-04  32.721670  tasmin\n",
       "2013-12-05  27.163567  tasmin\n",
       "2013-12-06  25.531320  tasmin\n",
       "2013-12-07  29.484454  tasmin\n",
       "2013-12-08  26.594804  tasmin\n",
       "2013-12-09  23.059196  tasmin\n",
       "2013-12-10  25.975196  tasmin\n",
       "2013-12-11  27.676846  tasmin\n",
       "2013-12-12  28.896392  tasmin\n",
       "2013-12-13  31.771010  tasmin\n",
       "2013-12-14  31.233794  tasmin\n",
       "2013-12-15  31.070309  tasmin\n",
       "2013-12-16  33.614804  tasmin\n",
       "2013-12-17  38.564804  tasmin\n",
       "2013-12-18  39.707526  tasmin\n",
       "2013-12-19  38.409113  tasmin\n",
       "2013-12-20  38.688206  tasmin\n",
       "2013-12-21  33.376350  tasmin\n",
       "2013-12-22  32.342186  tasmin\n",
       "2013-12-23  34.412557  tasmin\n",
       "2013-12-24  37.351196  tasmin\n",
       "2013-12-25  32.770845  tasmin\n",
       "2013-12-26  33.664722  tasmin\n",
       "2013-12-27  33.331815  tasmin\n",
       "2013-12-28  32.671196  tasmin\n",
       "2013-12-29  33.876083  tasmin\n",
       "2013-12-30  36.171361  tasmin\n",
       "2013-12-31  37.504474  tasmin\n",
       "\n",
       "[46752 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observedDF = get_observed()\n",
    "observedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download projected daily tasmax & tasmin for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    # Create an empty list to hold dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # Make a combined list of GCMs, scenarios, climate variables for looping\n",
    "    climvar = ['tasmax', 'tasmin']\n",
    "    period = ['day']\n",
    "    scenarios = ['rcp45', 'historical']\n",
    "    zipped = itertools.product(climvar, period, [name], scenarios)\n",
    "\n",
    "    # Loop through zipped\n",
    "    for item in zipped:\n",
    "        df = process_daily_data(item, data_download_params)\n",
    "        df_list.append(df)\n",
    "            \n",
    "    # Combine all the dataframes into one and return\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: tasmax_day_HadGEM2-ES_rcp45\n",
      "Processing: tasmax_day_HadGEM2-ES_historical\n",
      "Processing: tasmin_day_HadGEM2-ES_rcp45\n",
      "Processing: tasmin_day_HadGEM2-ES_historical\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>climvar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>48.389025</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02</th>\n",
       "      <td>43.415938</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>37.246958</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>42.387708</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>45.945194</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>44.388570</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-07</th>\n",
       "      <td>48.789552</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-08</th>\n",
       "      <td>46.718450</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>53.679605</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-10</th>\n",
       "      <td>54.822800</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-11</th>\n",
       "      <td>48.633632</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-12</th>\n",
       "      <td>54.489069</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-13</th>\n",
       "      <td>51.119143</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-14</th>\n",
       "      <td>52.723573</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-15</th>\n",
       "      <td>55.646688</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-16</th>\n",
       "      <td>50.980946</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-17</th>\n",
       "      <td>48.166743</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-18</th>\n",
       "      <td>50.303301</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-19</th>\n",
       "      <td>50.848730</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-20</th>\n",
       "      <td>51.912080</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-21</th>\n",
       "      <td>53.501722</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-22</th>\n",
       "      <td>58.466002</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-23</th>\n",
       "      <td>60.014617</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-24</th>\n",
       "      <td>59.608653</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-25</th>\n",
       "      <td>55.255511</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-26</th>\n",
       "      <td>54.950667</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-27</th>\n",
       "      <td>55.931418</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-28</th>\n",
       "      <td>57.788030</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-29</th>\n",
       "      <td>55.440027</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-30</th>\n",
       "      <td>56.018112</td>\n",
       "      <td>tasmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-02</th>\n",
       "      <td>55.183967</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-03</th>\n",
       "      <td>58.492822</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-04</th>\n",
       "      <td>60.830387</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-05</th>\n",
       "      <td>57.610437</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-06</th>\n",
       "      <td>43.646410</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-07</th>\n",
       "      <td>40.137345</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-08</th>\n",
       "      <td>41.286484</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-09</th>\n",
       "      <td>43.137333</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-10</th>\n",
       "      <td>42.968293</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-11</th>\n",
       "      <td>46.219377</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-12</th>\n",
       "      <td>42.773847</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-13</th>\n",
       "      <td>48.160980</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-14</th>\n",
       "      <td>36.544558</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-15</th>\n",
       "      <td>36.494940</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-16</th>\n",
       "      <td>46.934897</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-17</th>\n",
       "      <td>50.559615</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-18</th>\n",
       "      <td>46.155370</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-19</th>\n",
       "      <td>37.009816</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-20</th>\n",
       "      <td>28.064000</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-21</th>\n",
       "      <td>26.834800</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-22</th>\n",
       "      <td>30.913288</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-23</th>\n",
       "      <td>42.129581</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-24</th>\n",
       "      <td>32.621954</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-25</th>\n",
       "      <td>29.244779</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-26</th>\n",
       "      <td>35.993185</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-27</th>\n",
       "      <td>30.624282</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-28</th>\n",
       "      <td>31.761677</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-29</th>\n",
       "      <td>34.620641</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-30</th>\n",
       "      <td>37.365076</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-31</th>\n",
       "      <td>43.799576</td>\n",
       "      <td>tasmin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                value climvar\n",
       "2006-01-01  48.389025  tasmax\n",
       "2006-01-02  43.415938  tasmax\n",
       "2006-01-03  37.246958  tasmax\n",
       "2006-01-04  42.387708  tasmax\n",
       "2006-01-05  45.945194  tasmax\n",
       "2006-01-06  44.388570  tasmax\n",
       "2006-01-07  48.789552  tasmax\n",
       "2006-01-08  46.718450  tasmax\n",
       "2006-01-09  53.679605  tasmax\n",
       "2006-01-10  54.822800  tasmax\n",
       "2006-01-11  48.633632  tasmax\n",
       "2006-01-12  54.489069  tasmax\n",
       "2006-01-13  51.119143  tasmax\n",
       "2006-01-14  52.723573  tasmax\n",
       "2006-01-15  55.646688  tasmax\n",
       "2006-01-16  50.980946  tasmax\n",
       "2006-01-17  48.166743  tasmax\n",
       "2006-01-18  50.303301  tasmax\n",
       "2006-01-19  50.848730  tasmax\n",
       "2006-01-20  51.912080  tasmax\n",
       "2006-01-21  53.501722  tasmax\n",
       "2006-01-22  58.466002  tasmax\n",
       "2006-01-23  60.014617  tasmax\n",
       "2006-01-24  59.608653  tasmax\n",
       "2006-01-25  55.255511  tasmax\n",
       "2006-01-26  54.950667  tasmax\n",
       "2006-01-27  55.931418  tasmax\n",
       "2006-01-28  57.788030  tasmax\n",
       "2006-01-29  55.440027  tasmax\n",
       "2006-01-30  56.018112  tasmax\n",
       "...               ...     ...\n",
       "2005-12-02  55.183967  tasmin\n",
       "2005-12-03  58.492822  tasmin\n",
       "2005-12-04  60.830387  tasmin\n",
       "2005-12-05  57.610437  tasmin\n",
       "2005-12-06  43.646410  tasmin\n",
       "2005-12-07  40.137345  tasmin\n",
       "2005-12-08  41.286484  tasmin\n",
       "2005-12-09  43.137333  tasmin\n",
       "2005-12-10  42.968293  tasmin\n",
       "2005-12-11  46.219377  tasmin\n",
       "2005-12-12  42.773847  tasmin\n",
       "2005-12-13  48.160980  tasmin\n",
       "2005-12-14  36.544558  tasmin\n",
       "2005-12-15  36.494940  tasmin\n",
       "2005-12-16  46.934897  tasmin\n",
       "2005-12-17  50.559615  tasmin\n",
       "2005-12-18  46.155370  tasmin\n",
       "2005-12-19  37.009816  tasmin\n",
       "2005-12-20  28.064000  tasmin\n",
       "2005-12-21  26.834800  tasmin\n",
       "2005-12-22  30.913288  tasmin\n",
       "2005-12-23  42.129581  tasmin\n",
       "2005-12-24  32.621954  tasmin\n",
       "2005-12-25  29.244779  tasmin\n",
       "2005-12-26  35.993185  tasmin\n",
       "2005-12-27  30.624282  tasmin\n",
       "2005-12-28  31.761677  tasmin\n",
       "2005-12-29  34.620641  tasmin\n",
       "2005-12-30  37.365076  tasmin\n",
       "2005-12-31  43.799576  tasmin\n",
       "\n",
       "[109574 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectedDF = get_model('HadGEM2-ES')\n",
    "projectedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Calculate Degree Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_temp = 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heating Degree Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950-01-01    2557.536516\n",
       "1951-01-01    2757.516890\n",
       "1952-01-01    2897.365732\n",
       "1953-01-01    2666.221328\n",
       "1954-01-01    2842.955380\n",
       "1955-01-01    2926.215127\n",
       "1956-01-01    2771.236711\n",
       "1957-01-01    2730.596596\n",
       "1958-01-01    2322.724240\n",
       "1959-01-01    2238.973657\n",
       "1960-01-01    2638.744205\n",
       "1961-01-01    2926.790577\n",
       "1962-01-01    2890.715479\n",
       "1963-01-01    3068.462441\n",
       "1964-01-01    2794.810765\n",
       "1965-01-01    2800.790085\n",
       "1966-01-01    2461.303726\n",
       "1967-01-01    2947.403880\n",
       "1968-01-01    2614.531387\n",
       "1969-01-01    2700.340172\n",
       "1970-01-01    2462.958908\n",
       "1971-01-01    3172.806912\n",
       "1972-01-01    2914.982592\n",
       "1973-01-01    2593.613999\n",
       "1974-01-01    2673.965752\n",
       "1975-01-01    2924.168048\n",
       "1976-01-01    2232.655086\n",
       "1977-01-01    2448.175153\n",
       "1978-01-01    2450.412242\n",
       "1979-01-01    2532.564110\n",
       "                 ...     \n",
       "1984-01-01    2507.067024\n",
       "1985-01-01    2885.052830\n",
       "1986-01-01    2048.273324\n",
       "1987-01-01    2366.033877\n",
       "1988-01-01    2277.290735\n",
       "1989-01-01    2599.799791\n",
       "1990-01-01    2466.730672\n",
       "1991-01-01    2415.696663\n",
       "1992-01-01    2203.308253\n",
       "1993-01-01    2363.482755\n",
       "1994-01-01    2508.802362\n",
       "1995-01-01    1939.297943\n",
       "1996-01-01    2008.995707\n",
       "1997-01-01    1951.517525\n",
       "1998-01-01    2600.436757\n",
       "1999-01-01    2540.238792\n",
       "2000-01-01    2361.359559\n",
       "2001-01-01    2233.649230\n",
       "2002-01-01    2345.856647\n",
       "2003-01-01    2303.946450\n",
       "2004-01-01    2262.951114\n",
       "2005-01-01    2151.254881\n",
       "2006-01-01    2450.201133\n",
       "2007-01-01    2273.766365\n",
       "2008-01-01    2416.850599\n",
       "2009-01-01    2426.918763\n",
       "2010-01-01    2437.208020\n",
       "2011-01-01    2718.355209\n",
       "2012-01-01    2317.150220\n",
       "2013-01-01    2260.260275\n",
       "Freq: AS-JAN, Name: value, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average of tasmax & tasmin for each day\n",
    "observedAvg = observedDF.groupby(observedDF.index).mean()\n",
    "# Find days with average temperature below base temperature\n",
    "observedHDD = pd.DataFrame(observedAvg.loc[observedAvg['value'] < base_temp])\n",
    "# Calculate absolute value of difference between average temperature & base temperature\n",
    "observedHDD['value'] = abs(observedHDD['value'] - base_temp)\n",
    "# Sum total number of heating degrees by year\n",
    "observedHDD = observedHDD.value.resample('1AS').sum()\n",
    "observedHDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950-01-01    2742.273831\n",
       "1951-01-01    2501.170541\n",
       "1952-01-01    2505.054585\n",
       "1953-01-01    2294.225735\n",
       "1954-01-01    2389.738468\n",
       "1955-01-01    2649.696724\n",
       "1956-01-01    2503.488913\n",
       "1957-01-01    2611.369399\n",
       "1958-01-01    2606.452165\n",
       "1959-01-01    2917.804149\n",
       "1960-01-01    2445.666877\n",
       "1961-01-01    2563.254394\n",
       "1962-01-01    2592.987390\n",
       "1963-01-01    3012.010013\n",
       "1964-01-01    2864.506308\n",
       "1965-01-01    2412.403936\n",
       "1966-01-01    2380.803150\n",
       "1967-01-01    2919.901990\n",
       "1968-01-01    2629.730394\n",
       "1969-01-01    2530.029408\n",
       "1970-01-01    2351.352920\n",
       "1971-01-01    2611.795280\n",
       "1972-01-01    2264.456472\n",
       "1973-01-01    2458.241423\n",
       "1974-01-01    2340.860754\n",
       "1975-01-01    2523.804683\n",
       "1976-01-01    2783.033555\n",
       "1977-01-01    2531.997724\n",
       "1978-01-01    2426.253218\n",
       "1979-01-01    2821.723735\n",
       "                 ...     \n",
       "2070-01-01    2049.909130\n",
       "2071-01-01    1649.651691\n",
       "2072-01-01    1694.543678\n",
       "2073-01-01    1995.049321\n",
       "2074-01-01    1716.642088\n",
       "2075-01-01    2054.410826\n",
       "2076-01-01    1366.919658\n",
       "2077-01-01    1801.371832\n",
       "2078-01-01    1785.464238\n",
       "2079-01-01    1633.199460\n",
       "2080-01-01    2049.983337\n",
       "2081-01-01    1612.440858\n",
       "2082-01-01    1568.745027\n",
       "2083-01-01    1621.144654\n",
       "2084-01-01    1431.380816\n",
       "2085-01-01    1311.433979\n",
       "2086-01-01    1628.632539\n",
       "2087-01-01    1552.714831\n",
       "2088-01-01    1941.076728\n",
       "2089-01-01    1808.928264\n",
       "2090-01-01    1510.144494\n",
       "2091-01-01    1676.906894\n",
       "2092-01-01    1707.025778\n",
       "2093-01-01    1986.334627\n",
       "2094-01-01    1295.034946\n",
       "2095-01-01    1655.427096\n",
       "2096-01-01    1733.176508\n",
       "2097-01-01    1732.706417\n",
       "2098-01-01    1607.454712\n",
       "2099-01-01    1880.818814\n",
       "Freq: AS-JAN, Name: value, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average of tasmax & tasmin for each day\n",
    "projectedAvg = projectedDF.groupby(projectedDF.index).mean()\n",
    "# Find days with average temperature below base temperature\n",
    "projectedHDD = pd.DataFrame(projectedAvg.loc[projectedAvg['value'] < base_temp])\n",
    "# Calculate absolute value of difference between average temperature & base temperature\n",
    "projectedHDD['value'] = abs(projectedHDD['value'] - base_temp)\n",
    "# Sum total number of heating degree days by year\n",
    "projectedHDD = projectedHDD.value.resample('1AS').sum()\n",
    "projectedHDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooling Degree Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950-01-01    1226.595449\n",
       "1951-01-01    1026.217860\n",
       "1952-01-01    1151.352171\n",
       "1953-01-01     985.460288\n",
       "1954-01-01     934.968431\n",
       "1955-01-01    1032.311150\n",
       "1956-01-01    1030.875979\n",
       "1957-01-01    1113.157129\n",
       "1958-01-01    1336.122221\n",
       "1959-01-01    1228.642621\n",
       "1960-01-01    1272.584020\n",
       "1961-01-01    1316.073106\n",
       "1962-01-01     970.319115\n",
       "1963-01-01     978.804937\n",
       "1964-01-01    1030.546523\n",
       "1965-01-01     927.712452\n",
       "1966-01-01    1226.226768\n",
       "1967-01-01    1419.893979\n",
       "1968-01-01    1145.555212\n",
       "1969-01-01    1253.526761\n",
       "1970-01-01    1228.685782\n",
       "1971-01-01    1183.260697\n",
       "1972-01-01    1167.298843\n",
       "1973-01-01    1237.553347\n",
       "1974-01-01    1297.894775\n",
       "1975-01-01    1301.078973\n",
       "1976-01-01    1356.406912\n",
       "1977-01-01    1188.504322\n",
       "1978-01-01    1254.639933\n",
       "1979-01-01    1384.654476\n",
       "                 ...     \n",
       "1984-01-01    1627.669607\n",
       "1985-01-01    1277.191395\n",
       "1986-01-01    1155.900819\n",
       "1987-01-01    1330.214675\n",
       "1988-01-01    1557.380026\n",
       "1989-01-01    1191.794940\n",
       "1990-01-01    1493.951628\n",
       "1991-01-01    1418.066514\n",
       "1992-01-01    1597.517052\n",
       "1993-01-01    1316.416132\n",
       "1994-01-01    1273.317784\n",
       "1995-01-01    1263.195188\n",
       "1996-01-01    1616.651664\n",
       "1997-01-01    1651.001726\n",
       "1998-01-01    1216.136788\n",
       "1999-01-01    1212.895756\n",
       "2000-01-01    1336.758365\n",
       "2001-01-01    1571.808976\n",
       "2002-01-01    1426.716146\n",
       "2003-01-01    1633.282386\n",
       "2004-01-01    1485.890754\n",
       "2005-01-01    1325.940668\n",
       "2006-01-01    1486.293202\n",
       "2007-01-01    1306.335004\n",
       "2008-01-01    1473.786135\n",
       "2009-01-01    1432.189644\n",
       "2010-01-01    1187.846266\n",
       "2011-01-01    1244.912208\n",
       "2012-01-01    1439.704482\n",
       "2013-01-01    1349.963577\n",
       "Freq: AS-JAN, Name: value, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find days with average temperature above base temperature\n",
    "observedCDD = pd.DataFrame(observedAvg.loc[observedAvg['value'] > base_temp])\n",
    "# Calculate absolute value of difference between average temperature & base temperature\n",
    "observedCDD['value'] = abs(observedCDD['value'] - base_temp)\n",
    "# Sum total number of cooling degree days by year\n",
    "observedCDD = observedCDD.value.resample('1AS').sum()\n",
    "observedCDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950-01-01    1189.107535\n",
       "1951-01-01    1377.492386\n",
       "1952-01-01    1381.721695\n",
       "1953-01-01    1393.106304\n",
       "1954-01-01     966.717167\n",
       "1955-01-01    1018.426507\n",
       "1956-01-01    1203.997459\n",
       "1957-01-01    1488.415317\n",
       "1958-01-01    1254.158733\n",
       "1959-01-01    1343.965670\n",
       "1960-01-01    1380.141625\n",
       "1961-01-01    1401.698134\n",
       "1962-01-01    1082.034998\n",
       "1963-01-01     971.455716\n",
       "1964-01-01    1299.405471\n",
       "1965-01-01    1289.429195\n",
       "1966-01-01    1465.531027\n",
       "1967-01-01    1210.485517\n",
       "1968-01-01    1363.607785\n",
       "1969-01-01    1377.540234\n",
       "1970-01-01    1269.134621\n",
       "1971-01-01    1176.833920\n",
       "1972-01-01    1432.361182\n",
       "1973-01-01    1486.948414\n",
       "1974-01-01    1326.719616\n",
       "1975-01-01    1153.824214\n",
       "1976-01-01    1437.445081\n",
       "1977-01-01    1425.584567\n",
       "1978-01-01    1288.613411\n",
       "1979-01-01    1106.494829\n",
       "                 ...     \n",
       "2070-01-01    2714.598913\n",
       "2071-01-01    2511.503632\n",
       "2072-01-01    2410.734785\n",
       "2073-01-01    2067.844076\n",
       "2074-01-01    2749.656618\n",
       "2075-01-01    2587.979938\n",
       "2076-01-01    2373.495863\n",
       "2077-01-01    2019.454030\n",
       "2078-01-01    2514.181888\n",
       "2079-01-01    2370.830760\n",
       "2080-01-01    2439.540534\n",
       "2081-01-01    3067.764386\n",
       "2082-01-01    2168.056236\n",
       "2083-01-01    2689.987425\n",
       "2084-01-01    2492.252822\n",
       "2085-01-01    2787.725257\n",
       "2086-01-01    2609.323822\n",
       "2087-01-01    2655.607174\n",
       "2088-01-01    2233.156607\n",
       "2089-01-01    2177.562808\n",
       "2090-01-01    2400.592040\n",
       "2091-01-01    2710.635114\n",
       "2092-01-01    2303.800961\n",
       "2093-01-01    2349.986969\n",
       "2094-01-01    2699.724341\n",
       "2095-01-01    2651.556322\n",
       "2096-01-01    2027.405865\n",
       "2097-01-01    2604.592441\n",
       "2098-01-01    2441.618787\n",
       "2099-01-01    1934.985739\n",
       "Freq: AS-JAN, Name: value, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find days with average temperature above base temperature\n",
    "projectedCDD = pd.DataFrame(projectedAvg.loc[projectedAvg['value'] > base_temp])\n",
    "# Calculate absolute value of difference between average temperature & base temperature\n",
    "projectedCDD['value'] = abs(projectedCDD['value'] - base_temp)\n",
    "# Sum total number of heating degree days by year\n",
    "projectedCDD = projectedCDD.value.resample('1AS').sum()\n",
    "projectedCDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
